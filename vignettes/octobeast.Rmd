---
title: "The Octobeast"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The Octobeast}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(octomod)
library(broom)
library(dplyr)
```

# Introduction to the **Octobeast**

In supervised learning research projects, particularly those with multiple outcomes, the number of models and tests that are performed can become quite lengthy. The `octomod` package tries to tackle this by providing hypothesis and model organization.

By specifying at the beginning how a model or test should be setup, it becomes easier to implement the overall plan.

There are several basic functions:

-   `octomod()` initializes the modeling structure
-   `core()` defines the core data of the `octomod` structure, allowing tests to be performed from a centralized data set
-   `add_arm()` creates individual arms to the `octomod`, which reference a specific family of hypotheses
-   `equip()` gives each of the arms a *tidied* output including model fit and parameters, which can subsequently be called

## Arms of the `octomod`

The idea that each *arm* is a collection of hypothesis is important, as usually modeling involves testing several related hypotheses. The `add_arm()` function is nice because it allows a modular way to specify mulitple hypotheses.

For example, we could guess that in `iris`, the `Petal.Length` is likely dependent on both `Sepal.Length` and `Sepal.Width`. We could also guess that `Sepal.Length` and `Sepal.Width` may have the same distribution. This suggests two tests:

1.  Paired t-test to compare t-distribution of `Sepal.Length` and `Sepal.Width`
2.  Linear regression with `Petal.Length` as outcome, with `Sepal.Length`, `Sepal.Width` as predictors.
3.  Linear regression with `Petal.Width` as outcome, with `Sepal.Length` and `Sepal.Width` as predictors and `Species` as a fixed exposure

```{r}
# The data set that we will use
tibble::tibble(iris)

# The t-test
t.test(iris$Sepal.Length, iris$Sepal.Width, paired = TRUE)

# Regressions for petal length
lm(Petal.Length ~ Sepal.Length, data = iris) 
lm(Petal.Length ~ Sepal.Length + Sepal.Width, data = iris)

# Regressions for petal width
lm(Petal.Width ~ Species, data = iris)
lm(Petal.Width ~ Species + Sepal.Length, data = iris)
lm(Petal.Width ~ Species + Sepal.Width + Sepal.Length, data = iris)
```

This gives us three different tests for a single data set. The testing would be more elaborate in a larger dataset perhaps. The approach with `octomod` is to place each of these testing groups into an hypothetical *arm* and recall this data when needed.

The **approach** parameter allows for (currently), only either a *model\_spec* object from `parsnip`, or a simple statistical test from base `R` (e.g. `stats`) such as a t-test. If its a test from `stats`, can pass additional parameters within the `add_arm()` function.

```{r}
# Declare model type with parsnip
library(parsnip)
lm_mod <- 
  linear_reg() %>%
  set_engine("lm")

# Initial the structure
octobeast <-
  octomod() %>%
  # Add core data
  add_core(iris) %>%
  # Propose first hypothesis
  add_arm(
    title = "sepal_paired",
    f = Sepal.Length ~ Sepal.Width,
    approach = "t.test",
    paired = TRUE
  ) %>%
  # Specify first regression
  add_arm(
    title = "petal_length",
    f = Petal.Length ~ Sepal.Length + Sepal.Width,
    pattern = "parallel",
    approach = lm_mod
  ) %>%
  # Specify second regression
  add_arm(
    title = "petal_width",
    f = Petal.Width ~ Species + Sepal.Length + Sepal.Width,
    exposure = "Species",
    pattern = "sequential",
    approach = lm_mod
  ) %>%
  # Get the model and test fits
  equip()

# Here is what we've set up so far
octobeast
```

This structure holds the hypothesis we've declared, but we haven't fit or tested them yet. This allows flexibility in that it allows us to focus more on the planning component of hypothesis testing. It also highlights the **pattern** parameter, which reshapes the formulas into how the tests should be run, including having a fixed **exposure** parameter that doesn't vary. The **test\_num** states which iteration was run.

```{r}
# Parallel pattern
octobeast$arms$petal_length %>%
  select(test_num, formulas) %>%
  mutate(formulas = as.character(formulas))

# Sequential pattern with fixed exposure
octobeast$arms$petal_width %>%
  select(test_num, formulas) %>%
  mutate(formulas = as.character(formulas))
```

Now, we see how the fit all of the data at once (or in parts if we so choose using the **which\_arms** argument). We *equipped* each *arm* with the appropriate tested data. We can filter this down to what ever tests are most interesting.

```{r}
# List of fit
outfitted <-
  octobeast$outfit %>%
  bind_rows(.id = "arm") %>%
  tidyr::unnest(tidied)

# See the t-test results
outfitted %>%
  filter(arm == "sepal_paired")
  
# See the significant regression results
octobeast$outfit$petal_width %>%
  filter(test_num == 3) %>%
  tidyr::unnest(tidied)

# Compare with the lm
lm(Petal.Width ~ Species + Sepal.Length + Sepal.Width, data = iris) %>% tidy()
```
